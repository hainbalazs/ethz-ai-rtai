{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## How to construct the Toeplitz matrix?\n",
        "https://www.baeldung.com/cs/convolution-matrix-multiplication\n",
        "\n",
        "## How to compute the actual convolution?\n",
        "\n",
        "\n",
        "1.   Matrix multiplication along the N*N dimension (flattened input, and T)\n",
        "2.   Summation along the input channels\n",
        "3.   Redo the operation for each output channels, and concatenate\n",
        "\n"
      ],
      "metadata": {
        "id": "x-yNBL0wM68z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it together:"
      ],
      "metadata": {
        "id": "N_iS43iLzqNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy import linalg"
      ],
      "metadata": {
        "id": "SaAT5Z1K70zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same as: scipy.linalg.toeplitz\n",
        "def toeplitz_perfilter(row, N, K, stride):\n",
        "  # N is already padded\n",
        "  O = int(np.floor(((N - (K - 1) - 1) / stride) + 1))\n",
        "  # Repeat the kernel matrix J times\n",
        "  repeated_matrix = row.repeat(O, 1)\n",
        "\n",
        "  # Pad the matrix to be O*N\n",
        "  padded_matrix = F.pad(repeated_matrix, (0, N - row.size(0)))\n",
        "\n",
        "  # Shift them circularry by incrementally increasing amount\n",
        "  rolled_rows = [torch.roll(padded_matrix, shifts=i*stride, dims=1) for i in range(O)]\n",
        "  output = torch.stack(rolled_rows)[:, 0, :]\n",
        "\n",
        "  # Mask out the places of the 0s\n",
        "  i_indices, j_indices = torch.meshgrid(torch.arange(O), torch.arange(N))\n",
        "  mask = ((i_indices * stride > j_indices) | (j_indices >= i_indices * stride + row.size()[0]))\n",
        "  # Apply the mask\n",
        "  return torch.where(~mask, output, 0)\n",
        "\n",
        "\n",
        "def toeplitz_perchannel(kernel, input_size, stride=1):\n",
        "    \"\"\"\n",
        "    Output dim: (O**2, N**2)\n",
        "    where N is already padded\n",
        "    and O = floor(((N - (K - 1) - 1) / stride) + 1)\n",
        "    \"\"\"\n",
        "    # shapes\n",
        "    K = kernel.shape[0]\n",
        "    N = input_size[0]\n",
        "    O = int(np.floor(((N - (K - 1) - 1) / stride) + 1))\n",
        "\n",
        "    # from each row of the kernel construct a toeplitz matrix\n",
        "    W_conv = torch.zeros((O, O, N, N))\n",
        "    for r in range(K):\n",
        "        toeplitz = toeplitz_perfilter(kernel[r], N, K, stride)\n",
        "        #toeplitz2 = torch.tensor(linalg.toeplitz(c=(kernel[r,0], *np.zeros(N-K)), r=(*kernel[r], *np.zeros(N-K))))\n",
        "        for c in range(O):\n",
        "          # and create the doubly blocked W\n",
        "          W_conv[c, :, r+(c*stride), :] = toeplitz\n",
        "\n",
        "    return W_conv.reshape(O*O, N*N)\n",
        "\n",
        "\n",
        "def toeplitz_multichannel(kernel, input_size, padding=0, stride=1):\n",
        "    \"\"\"Compute toeplitz matrix for 2d conv with multiple in and out channels and batches.\n",
        "    Input dim: (in_ch, N, N)\n",
        "    Kernel dim: (out_ch, in_ch, K, K)\n",
        "    Output dim: (out_ch, in_ch, O**2, N**2)\n",
        "    where O = floor((N + 2*padding - (K - 1) - 1) / stride + 1)\n",
        "    \"\"\"\n",
        "    # idea is that for each output channel and input channel we want to create a Toeplitz map (reduce to the single channel case)\n",
        "    N = input_size[-1]\n",
        "    N_padded = N + 2*padding\n",
        "    K = kernel.shape[-1]\n",
        "    O = int(np.floor(((N + 2*padding - (K - 1) - 1) / stride) + 1))\n",
        "    In_Ch = input_size[0]\n",
        "    Out_Ch = kernel.shape[0]\n",
        "    output_size = (Out_Ch, In_Ch, O**2, N_padded**2)\n",
        "    T = torch.zeros(output_size)\n",
        "    for i,ks in enumerate(kernel):  # loop over output channel\n",
        "        for j,k in enumerate(ks):  # loop over input channel\n",
        "            T_k = toeplitz_perchannel(k, (N_padded, N_padded), stride)\n",
        "            T[i, j, :, :] = T_k\n",
        "\n",
        "    return T\n",
        "\n",
        "\n",
        "def toeplitz_multiply(W, B, X, output_dim):\n",
        "  out_filters = []\n",
        "\n",
        "  for Wo in W: # iterate through the output channels\n",
        "    in_channels = []\n",
        "    for i in range(Wo.shape[0]): # iterate through the input channels\n",
        "      Xi = X[i, :]\n",
        "      Wi = Wo[i, :, :]\n",
        "      in_channels.append(Wi @ Xi) # matmul as Conv2d for a single channel\n",
        "\n",
        "    F = torch.stack(in_channels)\n",
        "    out_filters.append(torch.sum(F, dim=0)) # sum over input channels\n",
        "\n",
        "  O = torch.stack(out_filters).reshape(-1, output_dim, output_dim) # stack the output channels\n",
        "  B = B.reshape(-1, 1, 1)\n",
        "  print(W.shape)\n",
        "  print(B.shape)\n",
        "  return O + B # add the bias\n"
      ],
      "metadata": {
        "id": "U6C9Iy66zuAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi channel case"
      ],
      "metadata": {
        "id": "RLbmgEF54rZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple convolutional layer\n",
        "padding = 1\n",
        "stride = 2\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=2, stride=stride, padding=padding)\n",
        "# Extract weights and bias\n",
        "weights = conv_layer.weight.data\n",
        "bias = conv_layer.bias.data\n",
        "\n",
        "#Define the input with size: (batch_size, channels, height, width)\n",
        "input_size = (1, 3, 3, 3)\n",
        "I = torch.randn(input_size)\n",
        "output_dim = int(np.floor((I.shape[-1] + 2*padding - (weights.shape[-1] - 1) - 1) / stride + 1))\n",
        "\n",
        "# Create the Toeplitz matrix transformation\n",
        "W = toeplitz_multichannel(weights, I.shape[1:], padding, stride)\n",
        "\n",
        "# Pad X accordingly\n",
        "X = F.pad(I, (padding, padding, padding, padding), \"constant\", 0)\n",
        "\n",
        "X = X.view(input_size[1], -1) # flatten 2D -> 1D\n",
        "\n",
        "# Conv2d as matrix multiplication\n",
        "r1 = toeplitz_multiply(W, bias, X, output_dim)\n",
        "\n",
        "# Compare the results\n",
        "r2 = conv_layer(I)\n",
        "\n",
        "print(\"Differenence between the outputs: \", torch.norm(r1-r2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f2LpvDd4vBT",
        "outputId": "199b6299-a50f-4e02-8ebd-79a43d91ee64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3, 4, 25])\n",
            "torch.Size([16, 1, 1])\n",
            "Differenence between the outputs:  tensor(2.9013e-07, grad_fn=<LinalgVectorNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single channel case"
      ],
      "metadata": {
        "id": "bqDUIXLV4z63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple convolutional layer\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, stride=1, padding=0)\n",
        "# Extract weights and bias\n",
        "weights = conv_layer.weight.data\n",
        "bias = conv_layer.bias.data\n",
        "\n",
        "#Define the input with size: (batch_size, channels, height, width)\n",
        "input_size = (1, 1, 3, 3)\n",
        "I = torch.randn(input_size)\n",
        "output_dim = I.shape[-1] - weights.shape[-1] + 1\n",
        "\n",
        "W = toeplitz_multichannel(weights, I.shape[1:])\n",
        "X = I.view(input_size[1], -1)\n",
        "\n",
        "r1 = toeplitz_multiply(W, bias, X, output_dim)\n",
        "r2 = conv_layer(I)\n",
        "print(\"Difference between the two outputs: \", torch.norm(r1-r2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi1xXXiQ4y-q",
        "outputId": "69461b30-51e7-442b-cb81-e44a5d9171d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 4, 9])\n",
            "torch.Size([1, 1, 1])\n",
            "Difference between the two outputs:  tensor(4.2147e-08, grad_fn=<LinalgVectorNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    }
  ]
}